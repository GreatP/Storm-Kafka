# 单机搭建

此模式主要用于 **开发人员本地环境下测试代码**

## 1 Zookeeper

### 1.1 解压 Zookeeper 并进入其根目录

```bash
tar -xzf zookeeper-3.4.9.tar.gz -C /usr/local/
cd /usr/local/zookeeper-3.4.9
```

### 1.2 创建配置文件 conf/zoo.cfg

```bash
cp conf/zoo_sample.cfg conf/zoo.cfg
```

### 1.3 修改内容如下:

```bash
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/var/lib/zookeeper/data
dataLogDir=/var/lib/zookeeper/log
clientPort=2181
```

* tickTime: 是 zookeeper 的最小时间单元的长度(以毫秒为单位), 它被用来设置心跳检测和会话最小超时时间(tickTime 的两倍)
* initLimit: 初始化连接时能容忍的最长 tickTime 个数
* syncLimit: follower 用于同步的最长 tickTime 个数
* dataDir: 服务器存储 **数据快照** 的目录
* dataLogDir: 服务器存储 **事务日志** 的目录
* clientPort: 用于 client 连接的 server 的端口

其中需要注意的是`dataDir`和`dataLogDir`, 分别是 zookeeper 运行时的数据目录和日志目录, 要保证 **这两个目录已创建** 且 **运行 zookeeper 的用户拥有这两个目录的所有权**

### 1.4 测试

启动/关闭 Zookeeper:

```bash
bin/zkServer.sh start
bin/zkServer.sh stop
```

使用 java 客户端连接 ZooKeeper

```bash
./bin/zkCli.sh -server 127.0.0.1:2181
```

然后就可以使用各种命令了, 跟文件操作命令很类似, 输入 help 可以看到所有命令.

## 2 Storm

### 2.1 搭建 Zookeeper

见 [1 Zookeeper](# 1 Zookeeper)

### 2.2 安装 Storm 依赖库(Java、Python)

在集群中的所有机器上安装 Storm 必要的依赖组件: Java7(or 8), Python2.7.

使用 CentOS 7 自带的 Python 2.7.5 及 openjdk 1.8.0_65 即可

### 2.3 解压 Storm 并进入其根目录

```bash
tar -xzf apache-storm-1.0.2.tar.gz -C /usr/local/
cd /usr/local/apache-storm-1.0.2
```

### 2.4 修改 conf/storm.yaml 配置文件

storm.yaml 会覆盖 defaults.yaml 中各个配置项的默认值, 以下几个是在安装集群时必须配置的选项

```bash
########### These MUST be filled in for a storm configuration
# yaml 文件的配置使用"-"来表示数据的层次结构, 配置项的:后必须有空格, 否则该配置项无法识别
# Storm 关联的 ZooKeeper 集群的地址列表
storm.zookeeper.servers:
    - "localhost"

# 如果使用的 ZooKeeper 集群的端口不是默认端口, 还需要配置 storm.zookeeper.port
# storm.zookeeper.port: 2181

# Storm 工作目录, 需要提前创建该目录并给以足够的访问权限
storm.local.dir: "/var/lib/storm"

# 用作 nimbus 的机器的 host list, 若 nimbus 是单机, 可以使用 nimbus.seeds: ["nim1"], 这里用的双机
# 若是填写 IP, 在 Storm UI 中显示不正常
nimbus.seeds: ["localhost"]

# Supervisor工作节点上 worker 的端口, 每个 worker 占用一个单独的端口用于接收消息, 有几个端口就最多会有几个 worker 运行, 这里配置了 4 个
supervisor.slots.ports:
    - 6700
    - 6701
    - 6702
    - 6703
```

### 2.5 启动 Storm 各个后台进程

和 Zookeeper 一样, Storm 也是快速失败(fail-fast)的系统, 这样 Storm 才能在任意时刻被停止, 并且当进程重启后被正确地恢复执行. 这也是为什么 Storm 不在进程内保存状态的原因, 即使 Nimbus 或 Supervisors 被重启, 运行中的 Topologies 不会受到影响. 以下是启动 Storm 各个后台进程的方式:

```bash
# 启动 Nimbus 后台程序, 并放到后台执行, 标准输出和错误输出定向到 `./logs/nimbus-boot.log`, 有问题时可以去看这个文件
nohup bin/storm nimbus > logs/nimbus-boot.log 2>&1 &

# 启动 Supervisor 后台程序, 并放到后台执行, 标准输出和错误输出定向到 `./logs/supervisor-boot.log`, 有问题时可以去看这个文件
nohup bin/storm supervisor > logs/supervisor-boot.log 2>&1 &

# 启动 Storm UI 后台程序, 并放到后台执行, 标准输出和错误输出定向到 `./logs/ui-boot.log`, 有问题时可以去看这个文件.
nohup bin/storm ui > logs/ui-boot.log 2>&1 &

# 启动 logviewer 后台程序, 并放到后台执行, 标准输出和错误输出定向到 `./logs/logviewer-boot.log`, 有问题时可以去看这个文件.
nohup bin/storm logviewer > logs/logviewer-boot.log 2>&1 &
```

Storm UI 可以在浏览器中方便地监控集群与拓扑运行状况, 启动后可以通过 *http://{nimbus host}:8080* 观察集群的 Worker 资源使用情况、Topologies 的运行状态等信息. Logviewer 是 Storm UI 中用来查看 Nimbus/Supervisor 的 log 的工具.

**Storm 后台进程被启动后, 将在 Storm 安装部署目录下的 logs/ 子目录下生成各个进程的日志文件, 这是 Storm 的默认设置, 日志文件的路径与相关配置信息可以在 {STORM_HOME}/logback/cluster.xml 文件中修改.**

至此, Storm 集群已经部署、配置完毕, 可以 向集群 提交拓扑 运行了.

### 2.6 查看 Storm 状态

利用 Storm UI, 通过 http://{nimbus host}:8080 查看集群的各种状态.

## 3 Kafka

#### 3.1 搭建 Zookeeper

Broker(即Kafka 的 server), Producer, Consumer 的运行都需要 ZooKeeper

见 [1 Zookeeper](# 1 Zookeeper)

### 3.2 Broker 的配置

```bash
tar -xzf kafka_2.11-0.9.0.1.tgz -C /usr/local/
cd /usr/local/kafka_2.11-0.9.0.1
```

config 文件夹下是各个组件的配置文件, server.properties 是 Broker 的配置文件, 需要修改和注意的有

```bash
broker.id=0                    # 本 Broker 的 id, 只要非负数且各 Broker 的 id 不同即可, 一般依次加 1
listeners=PLAINTEXT://:9092    # Broker 监听的端口, Producer, Consumer 会连接这个端口
port=9092                      # 同上
log.dirs=/var/lib/kafka        # log 目录, 此目录要存在且有足够权限
host.name=kfk1                 # 本 Broker 的 hostname
zookeeper.connect=zoo1:2181,zoo2:2181,zoo3:2181 # Zookeeper 的连接信息
```

#### 3.3 Broker 运行与终止

Broker 运行与终止命令如下. 运行时将 Broker 放到后台执行, 且不受终端关闭的影响, 标准输出和错误输出定向到 `./logs/kafka-server-boot.log`, 有问题时可以去看这个文件

```bash
# 运行
nohup bin/kafka-server-start.sh config/server.properties > logs/kafka-server-boot.log 2>&1 &

# 终止
bin/kafka-server-stop.sh config/server.properties
```

#### 3.4 测试

我们使用 Kafka 自带的基于 终端 的 Producer 和 Consumer 脚本做测试.

##### 1. 启动 Broker

```bash
> nohup bin/kafka-server-start.sh config/server.properties > logs/kafka-server-boot.log 2>&1 &
```

##### 2. 创建 Topic

创建一个 名为"TestCase"的 单分区 单副本 的 Topic.

```
> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic TestCase
```

查看这个 Topic:

```
> bin/kafka-topics.sh --list --zookeeper localhost:2181
TestCase
```

另外, 除去手工创建 Topic 以外, 你也可以将你的 Brokers 配置成当消息发布到一个不存在的 Topic 时自动创建此 Topics.

##### 3. 启动 生产者

Kafka 附带一个 **终端生产者** 可以从文件或者标准输入中读取输入然后发送这个消息到 Kafka 集群. 默认情况下每行信息被当做一个消息发送.

运行生产者脚本然后在终端中输入一些消息, 即可发送到 Broker.

```
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic TestCase
This is a message
This is another message
```

PS: 通过键入 **Ctrl-C** 来终止终端生产者.

##### 4. 启动 消费者

Kafka 也附带了一个 **终端生产者** 可以导出这些消息到标准输出.

```
> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic TestCase --from-beginning
This is a message
This is another message
```

如果你在不同的终端运行生产者和消费者这两个命令, 那么现在你就应该能再生产者的终端中键入消息同时在消费者的终端中看到.

所有的命令行工具都有很多可选的参数; 不添加参数直接执行这些命令将会显示它们的使用方法, 更多内容可以参考他们的手册.

PS: 通过键入 **Ctrl-C** 来终止终端消费者.
